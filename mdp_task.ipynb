{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Step 1) Create random MDP task structure given predefined parameters.\n",
    "\n",
    "MDP is defined as 5-tuple $\\left(S,A,P_a,R_a,\\gamma\\right)$. Algorithm creates random transition probability matrices, and reward matrices for each action $a\\in A$. Expected reward depends on realized 3-tuple $(s,a,s')$, where $s,s'\\in S$. Therefore, entire MDP comprised of $N=|S|$ states can be completely represented by four $N\\times N$ square matrices:\n",
    "- `P_left` transition probability matrix after choosing $a=L$\n",
    "- `P_right` transition probability matrix after choosing $a=R$\n",
    "- `Rval_left` and `Runc_left` reward matrix and reward noise matrix after choosing $a=L$\n",
    "- `Rval_right` and `Runc_right` reward matrix and reward noise matrix after choosing $a=R$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f \n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#=== MDP parameters ===\n",
    "#--- system dynamics\n",
    "N_states = 5 \n",
    "tran_possib = [[.5,.5]]          # possible transition probabilities\n",
    "tran_determ_frac = 0.5           # proportion of deterministic transitions\n",
    "#--- reward dynamics\n",
    "reward_trans_frac = 1/3          # proportion of rewarded transitions \n",
    "reward_noise = [1,2]             # possible reward noise\n",
    "reward_mean = 2                  # mean reward for rewarded transitions\n",
    "\n",
    "#=== TRANSITION PROBABILITY MATRIX ===\n",
    "#--- create empty transition probability matrix for all actions\n",
    "P = np.zeros([2*N_states, N_states])\n",
    "#--- ensure that all states are reachable and escape'able\n",
    "while (0 in np.sum(P, axis=0)) or (2 in np.diag(P[0:N_states]+P[N_states:])):\n",
    "    P = np.zeros([2*N_states, N_states])\n",
    "    #--- number of deterministic transitions for all 2N (s,a) pairs\n",
    "    N_tran_determ = int(np.ceil(2 * N_states * tran_determ_frac))\n",
    "    #--- store transition types (deterministic [code -1] vs. probabilistic [code 0,1,...])\n",
    "    tran_type = np.concatenate(((-1)*np.ones(N_tran_determ),\n",
    "                                [random.randint(0, len(tran_possib)-1) for trans in range(2*N_states - N_tran_determ)]))\n",
    "    np.random.shuffle(tran_type)\n",
    "    #--- fill transition matrices\n",
    "    for s in range(2*N_states):\n",
    "        if tran_type[s] == -1:\n",
    "            #--- deterministic transition to random successor state\n",
    "            P[s][random.randint(0, N_states-1)] = 1\n",
    "        else:\n",
    "            newrow = np.concatenate((tran_possib[int(tran_type[s])],\n",
    "                                    np.zeros(N_states-len(tran_possib[int(tran_type[1])]))))\n",
    "            np.random.shuffle(newrow)\n",
    "            P[s] = newrow\n",
    "#--- divide matrices \n",
    "P_left = P[0:N_states]\n",
    "P_right = P[N_states:]\n",
    "\n",
    "#=== REWARD VALUE and REWARD UNCERTAINTY MATRIX ===\n",
    "N_trans = np.sum(P>0)\n",
    "#--- number of rewarded transitions\n",
    "N_reward_trans = int(np.sum(P>0)*reward_trans_frac)\n",
    "#--- store reward values and their uncertainties\n",
    "reward_val = np.concatenate((np.random.multinomial(N_reward_trans*reward_mean, np.ones(N_reward_trans)/N_reward_trans, size=1)[0],\n",
    "                            np.zeros(N_trans-N_reward_trans)))\n",
    "reward_unc = np.concatenate(([reward_noise[random.randint(0,len(reward_noise)-1)] for i in range(N_reward_trans)],\n",
    "                            np.zeros(N_trans-N_reward_trans)))\n",
    "reward_info = np.vstack([reward_val, reward_unc])\n",
    "reward_info = np.random.permutation(reward_info.T).T\n",
    "#--- create empty reward matrix and reward uncertainty matrix for all actions\n",
    "Rval = np.zeros([2*N_states, N_states])\n",
    "Runc = np.zeros([2*N_states, N_states])\n",
    "#--- loop over transition probability matrix\n",
    "k = 0\n",
    "for idx in range(P.shape[0]):\n",
    "    for idy in range(P.shape[1]):\n",
    "        if P[idx,idy]>0:\n",
    "            Rval[idx,idy] = reward_info[0][k]\n",
    "            Runc[idx,idy] = reward_info[1][k]\n",
    "            k += 1\n",
    "#--- divide matrices\n",
    "Rval_left = Rval[0:N_states]\n",
    "Rval_right = Rval[N_states:]\n",
    "Runc_left = Runc[0:N_states]\n",
    "Runc_right = Runc[N_states:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== Loading random stimuli\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "#--- path to stimuli folder\n",
    "stimuli_path = 'stimuli/'\n",
    "\n",
    "#--- get stimuli and randomly draw N_states\n",
    "icon = os.listdir(stimuli_path)\n",
    "shuffle(icon)\n",
    "icon = [f'{stimuli_path}{icon[idx]}' for idx in range(N_states)]\n",
    "\n",
    "def drawstate(icon, index, size):\n",
    "    #--- read image\n",
    "    img = mpimg.imread(icon[index])\n",
    "    #--- draw image\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    ax.imshow(img)\n",
    "    plt.axis('off');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Step 2) Try out MDP task!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load predefined game settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "N_states = 5\n",
    "\n",
    "def drawstate(icon, index, size):\n",
    "    #--- read image\n",
    "    img = mpimg.imread(icon[index])\n",
    "    #--- draw image\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    ax.imshow(img)\n",
    "    plt.axis('off');\n",
    "    plt.show()\n",
    "    \n",
    "#--- transition probability matrix\n",
    "P_right = [[0   , 0.75, 0.25, 0,    0   ],\n",
    "           [0   , 0   , 0.  , 0.5 , 0.5 ],\n",
    "           [0.25, 0   , 0.75, 0   , 0   ], #self rewarding loop\n",
    "           [0   , 1   , 0.  , 0   , 0   ],\n",
    "           [0   , 0   , 0.  , 1   , 0   ]]\n",
    "P_left = [[1   , 0   , 0   , 0   , 0   ],\n",
    "          [0   , 0.5 , 0   , 0   , 0.5 ],\n",
    "          [1   , 0   , 0   , 0   , 0   ],\n",
    "          [0.  , 0   , 0   , 0   , 1   ],\n",
    "          [0   , 0.5 , 0.5 , 0   , 0   ]]\n",
    "\n",
    "#--- reward matrix\n",
    "Rval_right = [[0 , 0 , 0 , 0 , 0 ],\n",
    "              [0 , 0 , 0 , 1 , 0 ],\n",
    "              [0 , 0 , .5, 0 , 0 ], #self reward magnitude\n",
    "              [0 , 0 , 0 , 0 , 0 ],\n",
    "              [0 , 0 , 0 , 0 , 0 ]]\n",
    "Rval_left = [[0 , 0 , 0 , 0 , 0 ], \n",
    "             [0 , 0 , 0 , 0 , 0 ],\n",
    "             [0 , 0 , 0 , 0 , 0 ],\n",
    "             [0 , 0 , 0 , 0 , -1], #penalty\n",
    "             [0 , 3 , 6 , 0 , 0 ]]\n",
    "\n",
    "#--- reward noise matrix\n",
    "Runc_right = [[0 , 0 , 0 , 0 , 0 ],\n",
    "              [0 , 0 , 0 , 1 , 0 ],\n",
    "              [0 , 0 , 0 , 0 , 0 ], #self rewarding variability \n",
    "              [0 , 0 , 0 , 0 , 0 ],\n",
    "              [0 , 0 , 0 , 0 , 0 ]]\n",
    "Runc_left = [[1 , 0 , 0 , 0 , 0 ], #noisy self-loop\n",
    "             [0 , 0 , 0 , 0 , 0 ],\n",
    "             [0 , 0 , 0 , 0 , 0 ],\n",
    "             [0 , 0 , 0 , 0 , 0 ], #penalty noise \n",
    "             [0 , 1 , 2 , 0 , 0 ]] #big rewards\n",
    "\n",
    "P_right = np.asarray(P_right)\n",
    "P_left = np.asarray(P_left)\n",
    "Rval_right = np.asarray(Rval_right)\n",
    "Rval_left = np.asarray(Rval_left)\n",
    "\n",
    "#--- stimulis \n",
    "icon = ['stimuli/icons8-MouseAnimal-96.png',      # s0\n",
    "        'stimuli/icons8-Chewbacca-96.png',        # s1 \n",
    "        'stimuli/icons8-SockPuppet-96.png',       # s2\n",
    "        'stimuli/icons8-UgandanKnuckles-96.png',  # s3\n",
    "        'stimuli/icons8-Bastet-96.png']           # s4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run code below to play the game!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task complete, thank you for participation!\n",
      "You collected 149.6 points\n"
     ]
    }
   ],
   "source": [
    "#=== Run task!\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "import time\n",
    "\n",
    "#--- settings \n",
    "N_trials = 180\n",
    "t_isi = 3\n",
    "\n",
    "#--- reset game history \n",
    "state_history = np.zeros(N_trials+1)\n",
    "reward_history = np.zeros(N_trials+1); reward_history[0] = 0\n",
    "decision_history = ['none']\n",
    "\n",
    "#--- set initial state and reset trial counter\n",
    "trial = 0\n",
    "current_state = random.randint(0,N_states-1)\n",
    "state_history[trial] = current_state\n",
    "\n",
    "#--- welcome screen\n",
    "print('Welcome my friend!')\n",
    "name = input('Write your name, and press enter.')\n",
    "\n",
    "for t in range(N_trials):\n",
    "    #=== choice phase ===\n",
    "    clear_output()\n",
    "    print(f'Account: {np.round(sum(reward_history),1)}')\n",
    "    drawstate(icon, current_state, size=3)\n",
    "    decision = 0\n",
    "    while not (decision == '4' or decision == '6'): \n",
    "        decision = input('Choose?')\n",
    "    #====================\n",
    "\n",
    "    #--- choose transition & reward    \n",
    "    if decision == '4': #left\n",
    "        next_state = np.random.choice(N_states, 1, p=P_left[current_state])[0]\n",
    "        r = Rval_left[current_state][next_state] + np.round(np.random.normal(loc=0, scale=Runc_left[current_state][next_state]), 1)\n",
    "    elif decision == '6': #right\n",
    "        next_state = np.random.choice(N_states, 1, p=P_right[current_state])[0]\n",
    "        r = Rval_right[current_state][next_state] + np.round(np.random.normal(loc=0, scale=Runc_right[current_state][next_state]), 1)\n",
    "    #--- update history\n",
    "    reward_history[trial+1] += r\n",
    "    state_history[trial+1] = next_state\n",
    "    decision_history.append(decision)\n",
    "\n",
    "    #=== outcome phase ===\n",
    "    clear_output()\n",
    "    print(f'Reward: {np.round(r,1)}')\n",
    "    print(f'Account: {np.round(sum(reward_history),1)}')\n",
    "    drawstate(icon, next_state, size=1)\n",
    "    #--- update timestep\n",
    "    trial += 1\n",
    "    current_state = next_state\n",
    "    time.sleep(t_isi)\n",
    "    #=====================\n",
    "\n",
    "#--- end screen \n",
    "clear_output()\n",
    "print('Task complete, thank you for participation!')\n",
    "print(f'You collected {np.round(sum(reward_history),1)} points')\n",
    "\n",
    "#--- save task data for participant\n",
    "import pandas as pd\n",
    "\n",
    "d = {'states': state_history,\n",
    "    'decisions': decision_history,\n",
    "    'rewards': reward_history}\n",
    "df = pd.DataFrame(d)\n",
    "df.to_csv(f'{name+\"_mdptask.log\"}', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Step 3) Solve MDP using value iteration algorithm\n",
    "- Input: system dynamics (`P_right`,`P_left`), reward function (`Rval_left`,`Rval_right`)\n",
    "\n",
    "- Output: optimal policy $\\pi_*$ and value function $v_*$\n",
    "\n",
    "In value iteration following update is performed at each algorithm step \n",
    "$$v_{k+1}(s) = \\max\\limits_{a \\in A}\\left(R^a_s+\\gamma\\sum\\limits_{s'\\in S}P^a_{ss'}v_k\\left( s'\\right)\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== P(a=R) ===\n",
      "[[0.   0.75 0.25 0.   0.  ]\n",
      " [0.   0.   0.   0.5  0.5 ]\n",
      " [0.25 0.   0.75 0.   0.  ]\n",
      " [0.   1.   0.   0.   0.  ]\n",
      " [0.   0.   0.   1.   0.  ]]\n",
      "\n",
      "=== P(a=L) ===\n",
      "[[1.  0.  0.  0.  0. ]\n",
      " [0.  0.5 0.  0.  0.5]\n",
      " [1.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  1. ]\n",
      " [0.  0.5 0.5 0.  0. ]]\n",
      "\n",
      "=== R(a=R) ===\n",
      "[[0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1.  0. ]\n",
      " [0.  0.  0.5 0.  0. ]\n",
      " [0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0. ]]\n",
      "\n",
      "=== R(a=L) ===\n",
      "[[ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0 -1]\n",
      " [ 0  3  6  0  0]]\n",
      "\n",
      "State representations.\n",
      "\n",
      "State 0:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAABQJJREFUeJztmz1PI1cUht8zGBRo+BCCiCbeiHSbxAttUAwo/aZOwdhVuoDEDHKT0CHNFCz8AI9TpknYHwBLpDRBER9NimyxmFWkDUIBa9dGRmOfNMYyxDY2zJwZe+9TMXNnzj16uJy5c+9AzAyFDFrQCbxPKNmCKNmCKNmCKNmCKNmCKNmCKNmCKNmCKNmCKNmCKNmCKNmCKNmCRIJOwC8cx3kBIH77/N7eHorFYvWYmROO42QkcqJuXM92HOccwFCj9v39feTz+eoxMw87jnPhd15dV0YymUwcTUQDwNTUFAYHB2tPvfAzp2u6rowws157/OTDCcTGJ/Dy3zP89vq4en5iYgLMjL6+PgCImabZ0p/4x2Pj+Hbuq2NoWgKxx7vt5NZ1IxvAQu1BbHwCAPDJyCi+eRwDABQKBeTz+WvRbaF/EQdAUZTLmXbv7TrZzHzUqK2vJ4IP3BKy2SwKhULdazY3N7G1tdUw/vc//wRMfUqY+izabm5dJ1vTtMXaY+foD/x59g/evHuLN+/e4uDlX03vLxaLODk5QS6X8zy3rqvZuq7vOo5z49zvf78GAFxeXt55//T0NCYnJ28/QKsw88Z9c+s62QBARE+Y+eD2+dPT0zvvnZuba9acs217sdkFzehK2UdHR8e9vb3HAwMD0bGxMfT39+Pq6qphnW4FZs7ath19SF5d81JjmmaMmReI6N4jrxGWZZEXcTp+ZKdSqWipVPoBgE7kiZMbMPOsV7E6Uvby8vKCpmkZn7v51bKsuJcBO6qMmKYZA/C/B5+XMPOsbdu7fsTuiJFdKRWv/Irvp+BaOuKlxnVdP0dzTkI00AFlpNUFovvi1UyjFUJbRlKpVNR13QM/ZhhBEVrZpVLpVTeJBkJasw3DiAedgx+EUjYRieycAEAymeREIhGV6Ct0D0jTNHUAzl3XecXZ2dmN45mZGQC4YOatZDKZ8LKvMI5sMdFNGCIiPZ1Or3oZNIyyRenp6WnWvNCssV1CJXtpaanprrgfDA8PA0AWwPN0Ok2JRIIq6+FZTdM8LSOhmvpFIhHPl0dbYXR09CNmri4H6Lp+CCDqdT+hks3MMT/n1sy8QUTf1WsjovjOzg4DuNA07VE8Hvf8o51QlREi+tLP+LZtL1qWRfV24EdGRq5/HCqXy+c7OzurXvcfqpFNRCI127btWKO27e3tCyIaZOZFAKte9hsq2X5SLpeft3Ld/Py8b7/wUJURP9E0rfGXN0KEZmSvrKw89Ss2M/9o23bGr/itEpqRzcy/+BXbtm3dr9jtEArZhmE88yu2l7vjDyUUshvNfb1AasurFQKXbRiGX8upCcktr1YIdIm13q45M896uJ59aFnWE49iPZjAZNcRnQMQtyzrEPB2ozcsIzywMuK67o1FJ2Z+ei0aAIjoa2bOetFXZUMicAIb2YZhnNe+njcbfZXZSpyIPr9vf2EY3YG91FAby3sP+SY6TARWRohIrz02TfMglUpFg8lGhkBnI4ZhZIiouvXEzBeu6z5aX1/3/R9AgyDw3XXDMOINpnqHzLwbiUQ21tbWjoXT8oXAZddS+eRssVJi6v8HUQuE4WFYj1DJ7nYCf11/n1CyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBVGyBfkP3qiv40VyG3kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State 1:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State 2:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State 3:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAB0dJREFUeJztm11sFMcdwH9zNhfOGLwOYKqoke2GKg+uGlwJIZFUdVXSqpUIrM6gqq3ERyWkllQBVYWHRApRwkNAqKSKoJVaDlAekHKXtRupURVQHZE8QCTAKkhtqcVHIxoQ2HvxcQZz5+nDnj/Od2fv3q1n1+n8Xjh2Z/7z58fcf2dvZ4WUEo0aIkEn8P+Elq0QLVshWrZCtGyFaNkK0bIVomUrRMtWiJatEC1bIVq2QrRshWjZCtGyFVIfdAK1YsfNVxHsc91Bch0pdhnvvdc7d1mVR8zHhwd2t2kBG30JJjlspKzdvsSahXkn246bCQRbfQ7bh+A1412rz+e4Rcwb2Xa3eRFYNecD5Wk2LMuei9Dz4gJpd5sSFaIB6hiy4+arcxE61DPbNk2DOoYCSyBPp2FZl/wKF9qZXRD9t0CTiPg7fmhlF2a0mtJRCYFhx03fvlmhLCOFGh0eJDZjdBqWdb2WMKGb2Xbc3Bd0DiUIDOq4VmuY0MlGMCcrAT+wu82abqRCJduOm1uDzmEWrFo6h0a23W1uRJAIOo/ZsONm1eUkNLKpcdYoQ9Bmm6ZRTdcwyZ4/RNhVTbdQLP3suLnV9xKy7vvI762DZctKz929izjzIZz+sPr4kteMlLXPS5dwyPZ5XS3fehsaGoqOnTt3joMHDwJw5MgRWlpaIJtFvPRi1eMYSUt4aR+o7MHBwX1CiJKlnvhzL7xf5W/7a59DbttedKi7u7ukWUdHB3v27CF7PEHLpQvVjZWn3cuNTmA1e2ho6GI50QDyhQ0Qayh3albk2mddtbty5QpbtmzhzX/8s6pxAIh4e4ARiOz9+/f/kWm/e9y5c6eojfzd27D2OQCiq1fS9MZPMQ5txzi0ncZf/pCFP+gkunplafCnn/aUy5102lvyUxH81lPzIMrI+vXrZTabLTrW0NDAyZMnS9o2f/Gxq5j5W/cY/fQqD3OPuyoj47z4zDf57s3rrsYoh5e6HcgD3xUrVqSvXbvWNPVYR0fHxOcDBw5w/vx5AJ7tfIo9P3+exoaFM8ase2IpsQ1LiQG54UsML5784iSTyaIL5DitTz5Zk2ivBFJG2tvbk9OPbd68GYBEIjEhGuCTiwP85DfHPMWvlxkWZ/9OZOzBxLE1a9awc+dOli9fPnHs9fra//n2JrPLbdvAViM7duzIDAwMLGptbWXv3r3OUgw48aejvP/BmbJ9zhzzfi8xOpRnQfMCBGOzt/30KtlTZ70N4GG9Hfg62/79USnXPc+i2G2iuUEAMtkHvPmHXgY+G+L20APWdn6N13/1grKchg/1kr91z11jyUdGyupy0zR42YUbGuNQ8UWNRxlI/8v5/Pg3IBJVlpMcecgX+99Fjoy6aOxednh/G1nQCItbnc+Dl/2LO/K5E+/uBec/tAwi9hhLXt7kLp7gO26HDo3ssrPosaWTn+/1w0OXX+3pDN9w5N69APdvwVhhrOHrFbvkBm5XN9YMhGavX/qVdxCxKE1v/Kz4xLJvOZJk3pGW+cwpK6KucrCxUUgPQH6k9Fy0CRY9AXWxit3vJ87w6PINd4lLPnLXMEQzG5zZnX7lHR5dvll8YrycgCP9Xj88HIRcZvJYLgOjaUhfdcpEOdGLW2HJUzOKfvDXi+5FAwhc754KzcweR46Mcj9xGhGLsuTlzYhY1CknUQOyt52aCzOWgCIavwoLWyqefnT5JvcTp6tPWHDYddOwrEYqUbJKAadMZP4DY/nJ2V3f6PwZW1pc6ytQ1Zq6XH5hv133gv3rYzT+4kfUr/zK5MFI1CkHVZA58gG5gf/6k5zEQ70JWc2uROboX8j9+/Pa4/gp2sF1CYGwlRHJbmDjbGvXhh9/m+jqr88aW46Mkj111tsFzwNen9QEX0ak7EeIZySkm1PWYTtuGjCz7Oyps77UWxf0AhvKnpFs8xosBGVEHAcQsvBeTIQ+1RlIKP8EodJKI0+7kbKOex0neNljBbkRnH3QOSrthzYrSqkFyQ0hy0iVsr9Sl2o3WAYue3yz+fj7LJVesTCSVk9z0jLI016r9EL/E0bSEkbKakNMKxWS3UaqZxVjdJV0ztNc7bjB12xKv8YS0gKayrUtzKqJHUn2JrOrIKULKP1hyLmd7kNwyUhaPRVSmHysI2W/keoZn+kvTYu1rZb3bUIhW4jip9Qizyq3W3QL34g+P/JwLtI9k+IFU7eZnaimTk8l8DICkyVk4u81bjr3wtRtwCJfpmyAU7/z1W05m0ooZJfFWXOrwALeKrySN3Fxtk2zzclD9hupnlV+vK4X+E3NbEw8yfF4A+HDuD1I2WZMLSs1Et6ZXcBIWkJCWuVGeTtu7gLwUzTMA9kAIk8bwqd31V1iJC3fxwt9GfkyMS9m9pcFLVshWrZCtGyFaNkK0bIVomUrRMtWiJatEC1bIVq2QrRshWjZCtGyFaJlK0TLVoiWrRAtWyFatkK0bIVo2QrRshWiZStEy1aIlq0QLVsh/wPwjoOPLUr54gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State 4:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#=== Show MDP ===\n",
    "system = [P_right, P_left, Rval_right, Rval_left]\n",
    "labels = ['P(a=R)', 'P(a=L)', 'R(a=R)', 'R(a=L)']\n",
    "\n",
    "for idx, mat in enumerate(system):\n",
    "    print(f'\\n=== {labels[idx]} ===')\n",
    "    print(mat)\n",
    "\n",
    "print('\\nState representations.\\n')    \n",
    "    \n",
    "for s in range(N_states):\n",
    "    print(f'State {s}:')\n",
    "    drawstate(icon, s, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution found after 32 iterations!\n",
      "Value function = [2.4  4.01 1.68 3.55 6.49]\n",
      "Optimal policy = ['R', 'R', 'L', 'L', 'L']\n"
     ]
    }
   ],
   "source": [
    "gamma = .7 # discount rate \n",
    "value = np.zeros(N_states)\n",
    "\n",
    "#--- implementation details\n",
    "eps = .0001    # stopping condition\n",
    "delta = 2*eps  # initialize \n",
    "iteration = 0  # counter\n",
    "\n",
    "#--- value iteration algorithm\n",
    "while delta > eps:\n",
    "    #--- increment counter\n",
    "    iteration += 1\n",
    "    #--- calculate one step lookahead for both actions\n",
    "    v_left = np.sum(np.multiply(P_left,Rval_left), axis=1) + gamma * np.sum(np.multiply(P_left,value), axis=1)\n",
    "    v_right = np.sum(np.multiply(P_right,Rval_right), axis=1) + gamma * np.sum(np.multiply(P_right,value), axis=1)\n",
    "    #--- max over actions\n",
    "    v_new = np.maximum(v_left,v_right)\n",
    "    #--- update\n",
    "    delta = np.sum(abs(value - v_new))\n",
    "    value = v_new\n",
    "\n",
    "#--- get optimal policy     \n",
    "opt_policy = ['L'*int(b)+'R'*int(not b) for b in v_left > v_right]\n",
    "\n",
    "value = np.round(value, decimals=2)\n",
    "print(f'Solution found after {iteration} iterations!')\n",
    "print(f'Value function = {value}')\n",
    "print(f'Optimal policy = {opt_policy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
